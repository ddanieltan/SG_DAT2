{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classification\n",
    "\n",
    "Concepts in this Notebook:\n",
    "- Naive Bayes Classifiers\n",
    "- Train Test Split\n",
    "- Vectorizer (fit and transform)\n",
    "- Accuracy of training and test data\n",
    "- Sparse array vs normal array\n",
    "- Comparing classifiers in sklearn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some extra resources:\n",
    "\n",
    "- [SKL Naive Bayes Documentation](http://scikit-learn.org/stable/modules/naive_bayes.html)\n",
    "\n",
    "- [Stanford Naive Bayes Math](http://nlp.stanford.edu/IR-book/pdf/13bayes.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col_names =['critic','fresh','imdb','publication','quote','review_date','rtid','title']\n",
    "\n",
    "critics = pd.read_csv('https://raw.githubusercontent.com/gfleetwood/fall-2014-lessons/master/datasets/rt_critics.csv',header=None,names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The year's most inventive comedy.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critics.quote[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic</th>\n",
       "      <th>fresh</th>\n",
       "      <th>imdb</th>\n",
       "      <th>publication</th>\n",
       "      <th>quote</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rtid</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>critic</td>\n",
       "      <td>fresh</td>\n",
       "      <td>imdb</td>\n",
       "      <td>publication</td>\n",
       "      <td>quote</td>\n",
       "      <td>review_date</td>\n",
       "      <td>rtid</td>\n",
       "      <td>title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Derek Adams</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Time Out</td>\n",
       "      <td>So ingenious in concept, design and execution ...</td>\n",
       "      <td>2009-10-04</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Richard Corliss</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>TIME Magazine</td>\n",
       "      <td>The year's most inventive comedy.</td>\n",
       "      <td>2008-08-31</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>David Ansen</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Newsweek</td>\n",
       "      <td>A winning animated feature that has something ...</td>\n",
       "      <td>2008-08-18</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Leonard Klady</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Variety</td>\n",
       "      <td>The film sports a provocative and appealing st...</td>\n",
       "      <td>2008-06-09</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            critic  fresh      imdb    publication                                              quote  review_date    rtid      title\n",
       "0           critic  fresh      imdb    publication                                              quote  review_date    rtid      title\n",
       "1      Derek Adams  fresh  114709.0       Time Out  So ingenious in concept, design and execution ...   2009-10-04  9559.0  Toy story\n",
       "2  Richard Corliss  fresh  114709.0  TIME Magazine                  The year's most inventive comedy.   2008-08-31  9559.0  Toy story\n",
       "3      David Ansen  fresh  114709.0       Newsweek  A winning animated feature that has something ...   2008-08-18  9559.0  Toy story\n",
       "4    Leonard Klady  fresh  114709.0        Variety  The film sports a provocative and appealing st...   2008-06-09  9559.0  Toy story"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial vs Bernoulli Models\n",
    "\n",
    "- The **Multinomial model** actually counts occurences out of all possible occurences for probability - better for greater features\n",
    "- The **Bernoulli model** counts only all documents with presence of the word - better for fewer features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO - import both versions of naive bayes from sklearn\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How the Count Vectorizer Works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "\tMath is great\n",
      "\tMath is really great\n",
      "\tExciting exciting Math\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "### How the Count Vectorizer Works\n",
    "#\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "text = ['Math is great', 'Math is really great', 'Exciting exciting Math']\n",
    "print \"Original text:\\n\\t\", '\\n\\t'.join(text)\n",
    "\n",
    "# TODO - create the instance of CountVectorizer class. Specify the ngram_range argument (see docs)\n",
    "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "\n",
    "# TODO - call `fit` on the text to build the vocabulary\n",
    "vectorizer.fit(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: What is an ngram?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A: n-gram is a contiguous sequence of n items from a given sequence of text or speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'exciting',\n",
       " u'exciting exciting',\n",
       " u'exciting math',\n",
       " u'great',\n",
       " u'is',\n",
       " u'is great',\n",
       " u'is really',\n",
       " u'math',\n",
       " u'math is',\n",
       " u'really',\n",
       " u'really great']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the names of the features (n grams)\n",
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 8)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 6)\t1\n",
      "  (1, 7)\t1\n",
      "  (1, 8)\t1\n",
      "  (1, 9)\t1\n",
      "  (1, 10)\t1\n",
      "  (2, 0)\t2\n",
      "  (2, 1)\t1\n",
      "  (2, 2)\t1\n",
      "  (2, 7)\t1\n"
     ]
    }
   ],
   "source": [
    "# TODO call `transform` to convert text to a bag of words\n",
    "# x = ...\n",
    "# Document term matrix\n",
    "x = vectorizer.transform(text)\n",
    "print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1],\n",
       "       [2, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CountVectorizer uses a sparse array to save memory, but it's easier in this assignment to \n",
    "# convert back to a \"normal\" numpy array\n",
    "x_back = x.toarray()\n",
    "x_back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed text vector is \n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 8)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 6)\t1\n",
      "  (1, 7)\t1\n",
      "  (1, 8)\t1\n",
      "  (1, 9)\t1\n",
      "  (1, 10)\t1\n",
      "  (2, 0)\t2\n",
      "  (2, 1)\t1\n",
      "  (2, 2)\t1\n",
      "  (2, 7)\t1\n",
      "Words for each feature:\n",
      "[u'exciting', u'exciting exciting', u'exciting math', u'great', u'is', u'is great', u'is really', u'math', u'math is', u'really', u'really great']\n"
     ]
    }
   ],
   "source": [
    "print \"Transformed text vector is \\n\", x\n",
    "\n",
    "# `get_feature_names` tracks which word is associated with each column of the transformed x\n",
    "print \"Words for each feature:\"\n",
    "print vectorizer.get_feature_names()\n",
    "\n",
    "# Notice that the bag of words treatment doesn't preserve information about the *order* of words, \n",
    "# just their frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing our Features (X) and Target (Y) for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X is a (nreview, nwords) array. Each row corresponds to a bag-of-words representation for a single review. This will be the input to the model.\n",
    "\n",
    "Y is a nreview-element 1/0 array, encoding whether a review is Fresh (1) or Rotten (0). This is the desired output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Instantiate the vectorizer with n-grams of length one or two\n",
    "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "\n",
    "# Create a vector where each row is bag-of-words for a single quote\n",
    "X = vectorizer.fit_transform(critics.quote) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO - Create an array where each element encodes whether the array is Fresh or Rotten\n",
    "# Y = ...\n",
    "# hint: apply the == condition, then use .values.astype(np.int) on the result to get the right type\n",
    "\n",
    "Y = (critics.fresh == 'fresh').values.astype(np.int)\n",
    "Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use SKLearn's train_test_split\n",
    "# Important - we'll do this a thousand times\n",
    "from sklearn.cross_validation import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# vector of all quotes\n",
    "rotten_vectorizer = vectorizer.fit(critics.quote)\n",
    "\n",
    "# a few helper functions\n",
    "def accuracy_report(_clf):\n",
    "    print \"Accuracy: %0.2f%%\" % (100 * _clf.score(xtest, ytest))\n",
    "    # %0.2f add in answer to 2 dec. place\n",
    "    # %% print % symbol\n",
    "\n",
    "    #Print the accuracy on the test and training dataset\n",
    "    training_accuracy = _clf.score(xtrain, ytrain)\n",
    "    test_accuracy = _clf.score(xtest, ytest)\n",
    "\n",
    "    print \"Accuracy on training data: %0.2f\" % (training_accuracy)\n",
    "    \n",
    "# a function to run some tests\n",
    "def AnalyzeReview(testquote, _clf):\n",
    "    print \"\\\"\"  + testquote + \"\\\" is judged by clasifier to be...\"\n",
    "    testquote = rotten_vectorizer.transform([testquote])\n",
    "\n",
    "    if (_clf.predict(testquote)[0] == 1):\n",
    "        print \"... a fresh review.\"\n",
    "    else:\n",
    "        print \"... a rotten review.\"\n",
    "    return(_clf.predict(testquote)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10x163505 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 0 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotten_vectorizer.transform('This movie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB:\n",
      "Accuracy: 77.24%\n",
      "Accuracy on training data: 0.99\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "print \"MultinomialNB:\"\n",
    "clf_mn = MultinomialNB().fit(xtrain, ytrain)\n",
    "accuracy_report(clf_mn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB:\n",
      "Accuracy: 64.45%\n",
      "Accuracy on training data: 0.86\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "print \"BernoulliNB:\"\n",
    "# TODO - same as above with Bernoulli\n",
    "clf_b = BernoulliNB().fit(xtrain, ytrain)\n",
    "accuracy_report(clf_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "Accuracy: 77.21%\n",
      "Accuracy on training data: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "print \"Logistic Regression:\"\n",
    "# TODO - same as above with LogReg\n",
    "clf_lr = LogisticRegression().fit(xtrain, ytrain)\n",
    "accuracy_report(clf_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"This movie was awesome\" is judged by clasifier to be...\n",
      "... a fresh review.\n",
      "\"This movie was awesome\" is judged by clasifier to be...\n",
      "... a fresh review.\n",
      "\"This movie was awesome\" is judged by clasifier to be...\n",
      "... a rotten review.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AnalyzeReview(\"This movie was awesome\", clf_mn)\n",
    "AnalyzeReview(\"This movie was awesome\", clf_b)\n",
    "AnalyzeReview(\"This movie was awesome\", clf_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.39479469  0.02758775  0.08966509 ...,  0.06339393  0.03158208\n",
      "  0.08750306] [1 1 1 ..., 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Save prediction and probability\n",
    "\n",
    "# Outputs of X (just first column)\n",
    "prob = clf_lr.predict_proba(X)[:, 0]\n",
    "predict = clf_lr.predict(X)\n",
    "\n",
    "print prob, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False], dtype=bool)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y==0 #(provides a mask where the actual review is bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4925, 1408, 3850, 3532, 2369])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# argsort returns the positions of the top n sorted values\n",
    "np.argsort((prob[Y==0]))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Top 5 Review classification errors\n",
    "bad_rotten = np.argsort(prob[Y == 0])[:5]\n",
    "bad_fresh = np.argsort(prob[Y == 1])[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mis-predicted Rotten quotes\n",
      "---------------------------\n",
      "If you loved Wolfe's book, you may very well hate the movie. If you simply liked the novel, you may be simultaneously entertained and disappointed by what De Palma and Cristofer have done to it.\n",
      "\n",
      "Works best if you can switch off your brain. Those who can will reach weepy nirvana. Those who can't will find this sticky-sweet wallow a bit, well, dumb.\n",
      "\n",
      "What is strange is that Tough Guys Don't Dance leaves me with such vivid memories of its times and places, its feelings and weathers, and yet leaves me so completely indifferent to its plot. Watching the film, I laughed a good deal.\n",
      "\n",
      "What if this lesser-known chapter of German resistance had been more deeply captured? What if the moral conflicts running through this movie about love of country and revolt said more about Germany, war and, yes, genocide?\n",
      "\n",
      "Nava, who started his feature-film career with El Norte, is a good director who invariably finds a strong rapport with his actors. He's not much of a writer, though, and he should think twice about creating dialogue for his future projects.\n",
      "\n",
      "Mis-predicted Fresh quotes\n",
      "--------------------------\n",
      "This holiday contender from John Hughes is too crass, too loud and too violent to be added blithely to Christmas viewing traditions. But it is funny.\n",
      "\n",
      "There's not a believable minute in the 92 minutes of Last Chance Harvey, but Dustin Hoffman and Emma Thompson smooth over most of the problems just by showing up and doing what they do for a living.\n",
      "\n",
      "Though the script is predictable, it's not too clumsy.\n",
      "\n",
      "The movie's basic joke holds that the overbearing, unselfconscious Americans will do anything and say anything (and usually as loudly as possible), while the timorous British are nearly too polite to breathe.\n",
      "\n",
      "There's too much talent and too strong a story to mess it up. There was potential for more here, but this incarnation is nothing to be ashamed of, and some of the actors answer the bell.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ddan/anaconda2/lib/python2.7/site-packages/IPython/kernel/__main__.py:4: FutureWarning: irow(i) is deprecated. Please use .iloc[i] or .iat[i]\n",
      "/home/ddan/anaconda2/lib/python2.7/site-packages/IPython/kernel/__main__.py:10: FutureWarning: irow(i) is deprecated. Please use .iloc[i] or .iat[i]\n"
     ]
    }
   ],
   "source": [
    "print \"Mis-predicted Rotten quotes\"\n",
    "print '---------------------------'\n",
    "for row in bad_rotten:\n",
    "    print critics[Y == 0].quote.irow(row)\n",
    "    print\n",
    "\n",
    "print \"Mis-predicted Fresh quotes\"\n",
    "print '--------------------------'\n",
    "for row in bad_fresh:\n",
    "    print critics[Y == 1].quote.irow(row)\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
